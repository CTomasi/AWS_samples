{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with S3 Buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`boto3` is an SDK for working with AWS services in Python. This notebook explores ways to perform simple operations with the Amazon S3 cloud storage service. These operations involve creating and deleting S3 buckets and uploading and downloading files from them. There is much more to `boto3` than this, as you can find out in the <a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\">`boto3` documentation</a>.\n",
    "\n",
    "This notebook follows loosely some of the examples on <a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-creating-buckets.html\">this AWS documentation page</a> and on the pages thereafter.\n",
    "\n",
    "The examples are geared mainly to <a href=\"https://aws.amazon.com/sagemaker/\">SageMaker</a> users, but should be useful more broadly as well. They are meant to be run in a SageMaker Jupyter notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    \"\"\"Create an S3 bucket in a specified region\n",
    "    If a region is not specified, the bucket is created in the S3 default\n",
    "    region (us-east-1).\n",
    "    :param bucket_name: Name of the bucket to create\n",
    "    :param region: String region to create bucket in, e.g., 'us-west-2'\n",
    "    :return: True if bucket created, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Create bucket\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client = boto3.client('s3')\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            s3_client = boto3.client('s3', region_name=region)\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration=location)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bucket-creation routine for SageMaker-accessible buckets and with Duke in its name, to promote consistent bucket naming conventions. We use our AWS region, `us-east-2` (Ohio), as the value for the `region` argument, since our resources are located there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_standard_bucket(suffix):\n",
    "    bucket_name = 'sagemaker-duke-' + suffix\n",
    "    return create_bucket(bucket_name, region='us-east-2'), bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True sagemaker-duke-carlo-test-2\n"
     ]
    }
   ],
   "source": [
    "response, full_bucket_name = create_standard_bucket('carlo-test-2')\n",
    "print(response, full_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if a Bucket Exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_exists(bucket_name, region='us-east-2'):\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        bucket = s3_client.head_bucket(Bucket=bucket_name)\n",
    "        region_found = bucket['ResponseMetadata']['HTTPHeaders']['x-amz-bucket-region']\n",
    "        if region is None:\n",
    "            return True\n",
    "        else:\n",
    "            return region_found == region\n",
    "    except ClientError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone actually created a public bucket `yada` in region `east-us-1`, so the command below should return true unless the bucket has been deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(bucket_exists('yada'))\n",
    "print(bucket_exists('yada', region=None))\n",
    "print(bucket_exists('yadazz'))\n",
    "print(bucket_exists(full_bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Buckets\n",
    "\n",
    "The following code lists all the buckets in the AWS account, and therefore needs the appropriate credentials to do so. You can achieve this by one of the methods described <a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\">here</a>.\n",
    "\n",
    "You can also define an appropriate role to use when creating a notebook instance. To check your current role do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::513002341673:role/sagemaker\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_buckets():\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_buckets()\n",
    "    return [bucket['Name'] for bucket in response['Buckets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-duke-carlo-test\n",
      "sagemaker-duke-carlo-test-2\n",
      "sagemaker-duke-carlo-tutorial\n",
      "sagemaker-duke-shuzhi\n",
      "sagemaker-duke-vision\n",
      "sagemaker-studio-5fixvt9sp9h\n",
      "sagemaker-studio-fgiy4vsxlzl\n",
      "sagemaker-studio-i0ft6t3t96c\n",
      "sagemaker-studio-r0xgnmr9u1n\n",
      "sagemaker-studio-tn7l6bfsx9\n",
      "sagemaker-studio-xtha4s3jd3\n"
     ]
    }
   ],
   "source": [
    "buckets = list_all_buckets()\n",
    "for bucket in buckets:\n",
    "    print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferring Files to and from Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name, bucket_name, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: Name of local file to upload\n",
    "    :param bucket_name: Name of the bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket_name, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!date > date.txt\n",
    "response = upload_file('date.txt', full_bucket_name)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(object_name, bucket_name, file_name=None):\n",
    "    \"\"\"Download an objet (file) from an S3 bucket\n",
    "\n",
    "    :param object_name: S3 name of object to download\n",
    "    :param bucket_name: Name of the bucket to downlaod from\n",
    "    :param object_name: Name of local file. If not specified then object_name is used\n",
    "    :return: True if file was downloaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if file_name is None:\n",
    "        file_name = object_name\n",
    "\n",
    "    # Download the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.download_file(bucket_name, object_name, file_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_copy.txt  date.txt\r\n"
     ]
    }
   ],
   "source": [
    "response = download_file('date.txt', full_bucket_name, 'date_copy.txt')\n",
    "!ls date*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting a Bucket\n",
    "\n",
    "The following code assumes that the bucket has no versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_bucket(bucket_name):\n",
    "    s3 = boto3.resource('s3')\n",
    "    if bucket_exists(bucket_name):\n",
    "        bucket = s3.Bucket(bucket_name)\n",
    "        bucket.objects.all().delete()\n",
    "        s3_client = boto3.client('s3')\n",
    "        s3_client.delete_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "delete_bucket(full_bucket_name)\n",
    "print(bucket_exists(full_bucket_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
